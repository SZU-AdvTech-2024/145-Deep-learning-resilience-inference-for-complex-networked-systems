 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.12it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 469.11it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.37it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.10it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 140.80it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.59it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.63it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.33it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.61it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.78it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.73it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.50it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.80it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.65it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 140.58it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.11it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.04it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 487.70it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.30it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.35it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 132.24it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.98it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.71it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.01it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 473.13it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.13it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.54it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.42it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.92it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.96it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.27it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.95it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.48it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.47it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.54it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.53it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.63it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.60it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.05it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.63it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 473.80it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.40it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.58it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.87it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.54it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 130.60it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.11it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.83it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.79it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.25it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.68it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.03it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.93it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.90it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.18it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.97it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.40it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.01it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.75it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.61it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 488.19it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.09it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 473.03it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.08it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.38it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.60it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.27it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.00it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.60it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.12it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.17it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.76it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.98it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.60it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.99it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.92it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.66it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.91it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.75it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.39it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.68it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.34it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.26it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.84it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.89it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.82it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.98it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.81it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.46it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.90it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.00it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.09it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.72it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.00it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.47it/s]
ResInf(
  (avg_pool): AdaptiveAvgPool2d(output_size=1)
  (max_pool): AdaptiveMaxPool2d(output_size=1)
  (sharedMLP): Sequential(
    (0): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): ReLU()
    (2): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (encoder_input_layer): Linear(in_features=1, out_features=8, bias=True)
  (positional_encoding_layer): PositionalEncoder(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (linear1): Linear(in_features=8, out_features=8, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=8, out_features=8, bias=True)
        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (gcns): ModuleList(
    (0): GCNConv(
      (linear): Linear(in_features=8, out_features=4, bias=True)
      (s_linear): Linear(in_features=8, out_features=4, bias=True)
    )
  )
  (hidden_layers): ModuleList(
    (0): Linear(in_features=4, out_features=4, bias=True)
    (1): Tanh()
  )
  (resi_net_Linear): Linear(in_features=4, out_features=3, bias=True)
  (resi_net_down): Linear(in_features=3, out_features=1, bias=True)
  (pred_linear): Linear(in_features=1, out_features=1, bias=True)
)
Namespace(lr=0.001, weight_decay=1e-05, dropout=0, hidden=2, time_tick=100, gpu=0, seed=2021, T=200.0, operator='norm_adj', epoch=50, train_size=1, valid_size=1, test_size=1, rand_guess=False, layers=1, use='start', type='node', causal=0, K=2, comment='normal', mech=1, asso=0, use_model='resinf', decompo='None', cross=0, save=1, emb_size=4, hidden_layers_num=2, pool_type='virtual', pool_arch='global', trans_layers=1, trans_emb_size=8, n_heads=1, finetune=0, train_type='kfold', threshold=0.5, fold_num=8, use_logitloss=False, use_wandb=True)
Total Loss in Epoch 0:
0.6381738483905792
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7232974767684937, 0.7227562069892883, 0.7231851816177368, 0.7241068482398987, 0.7227033376693726, 0.7238549590110779, 0.7228807806968689]
Current metric value better than 0.4155844155844156 better than best -inf, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124446-exx4y2q9/files/checkpoints/ResInf_epoch0.pt, & logging model weights to W&B.
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   0   | 0.6381738483905792 | 0.7362965047359467 | 0.5714285714285714 | 0.16666666666666669 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 1:
0.6369683669537914
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7196263074874878, 0.7207260727882385, 0.7197840809822083, 0.7195702195167542, 0.7202807068824768, 0.7210076451301575, 0.7193907499313354]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   1   | 0.6369683669537914 | 0.7324750466006142 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 2:
0.6365372477745523
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7163857817649841, 0.7187036871910095, 0.7166103720664978, 0.7161104083061218, 0.717961311340332, 0.718069851398468, 0.717481255531311]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   2   | 0.6365372477745523 | 0.7292979146753039 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 3:
0.6351969759075009
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7146879434585571, 0.7168427109718323, 0.7134218215942383, 0.7141025066375732, 0.71724933385849, 0.7173879742622375, 0.7136592864990234]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   3   | 0.6351969759075009 | 0.7272508953298841 | 0.5714285714285714 | 0.8333333333333334 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 4:
0.6341457117576988
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7108056545257568, 0.7159166932106018, 0.7101801633834839, 0.7101446390151978, 0.7178638577461243, 0.7121357321739197, 0.7111338376998901]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   4   | 0.6341457117576988 | 0.723367669752666 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 5:
0.6324336133441146
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7067837715148926, 0.709530770778656, 0.7065980434417725, 0.7052618265151978, 0.7157676219940186, 0.7099621891975403, 0.7055535316467285]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   5   | 0.6324336133441146 | 0.7205131522246769 | 0.5714285714285714 | 0.8333333333333334 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 6:
0.632519603991995
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.702732264995575, 0.7100488543510437, 0.7055506110191345, 0.7018331289291382, 0.7129244804382324, 0.7094659805297852, 0.70280921459198]
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   6   | 0.632519603991995 | 0.7175122925213405 | 0.5714285714285714 | 0.9166666666666667 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 7:
0.6293811171638722
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.7003799676895142, 0.715092658996582, 0.7001124620437622, 0.6990532875061035, 0.7198159694671631, 0.7056962251663208, 0.7032148241996765]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   7   | 0.6293811171638722 | 0.7107394422803607 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 8:
0.6270161362326875
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.692679226398468, 0.7304711937904358, 0.6967186331748962, 0.6913076639175415, 0.718844473361969, 0.7114347219467163, 0.6932435631752014]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   8   | 0.6270161362326875 | 0.6999126970767975 | 0.5714285714285714 | 0.9166666666666667 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 9:
0.6227367970408225
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6898460388183594, 0.7302725911140442, 0.6914690732955933, 0.687588095664978, 0.7274134755134583, 0.7054359912872314, 0.6922476887702942]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   9   | 0.6227367970408225 | 0.6942001070295062 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 10:
0.6219284358073254
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6823989748954773, 0.7112328410148621, 0.685689389705658, 0.6833544969558716, 0.7346906065940857, 0.7296922206878662, 0.6889823079109192]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   10  | 0.6219284358073254 | 0.6844340945993151 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 11:
0.6136252509087933
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6809943318367004, 0.7442912459373474, 0.6793975830078125, 0.6756503582000732, 0.7485156059265137, 0.7223203778266907, 0.6953761577606201]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   11  | 0.6136252509087933 | 0.6685154267719814 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 12:
0.604477945030952
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6608090400695801, 0.743240475654602, 0.6603223085403442, 0.6602915525436401, 0.7544572949409485, 0.7057667970657349, 0.6981960535049438]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   12  | 0.604477945030952 | 0.6466908071722303 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 13:
0.6008762042133176
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6519122123718262, 0.7665956020355225, 0.6690637469291687, 0.6549328565597534, 0.7664148807525635, 0.7488178610801697, 0.6856352686882019]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   13  | 0.6008762042133176 | 0.6319489819662911 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 14:
0.5946006257923282
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6446497440338135, 0.7546319961547852, 0.650622546672821, 0.6421455144882202, 0.7696657180786133, 0.6913184523582458, 0.6509280204772949]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   14  | 0.5946006257923282 | 0.6365310762609754 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 15:
0.6083642244338989
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6386882066726685, 0.7681909799575806, 0.6384751200675964, 0.6380038857460022, 0.7747199535369873, 0.7656851410865784, 0.6517767310142517]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   15  | 0.6083642244338989 | 0.6093669022832598 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 16:
0.5788447479812466
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.631942093372345, 0.7790973782539368, 0.638739824295044, 0.6340803503990173, 0.7770434021949768, 0.7730553150177002, 0.6725001335144043]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   16  | 0.5788447479812466 | 0.5970070553677422 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 17:
0.5851368329354695
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6263719201087952, 0.7725253105163574, 0.6278885006904602, 0.6255536079406738, 0.7873048782348633, 0.7736914157867432, 0.6324600577354431]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   17  | 0.5851368329354695 | 0.5953304874045509 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 18:
0.5607782468503836
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6177448034286499, 0.7950631380081177, 0.6223469376564026, 0.6154851317405701, 0.7952227592468262, 0.7937921285629272, 0.6263979077339172]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   18  | 0.5607782468503836 | 0.5783412626811436 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 19:
0.5828101726210847
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6113382577896118, 0.7961896657943726, 0.6117260456085205, 0.6103761196136475, 0.7908638715744019, 0.7935165762901306, 0.6244869828224182]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   19  | 0.5828101726210847 | 0.571188034755843 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 20:
0.5563098061449674
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.6024042963981628, 0.7910224795341492, 0.6055151224136353, 0.6021182537078857, 0.8037817478179932, 0.7936338782310486, 0.6380212903022766]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   20  | 0.5563098061449674 | 0.5582096534115928 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 21:
0.5504019032327496
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5960499048233032, 0.8077351450920105, 0.5975008010864258, 0.5971099734306335, 0.8081796169281006, 0.7356157898902893, 0.604354977607727]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   21  | 0.5504019032327496 | 0.566107234784535 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 22:
0.5673726082456355
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5866960883140564, 0.8059973120689392, 0.5870696902275085, 0.5898292660713196, 0.8106532096862793, 0.7757263779640198, 0.604545533657074]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   22  | 0.5673726082456355 | 0.5488648244312831 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 23:
0.5606393555597383
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5851680636405945, 0.7953224182128906, 0.5872555375099182, 0.5822025537490845, 0.8138254880905151, 0.749889075756073, 0.7391043305397034]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   23  | 0.5606393555597383 | 0.5232471610818591 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 24:
0.5563133024439519
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5830184817314148, 0.8154284954071045, 0.5816169381141663, 0.5797193050384521, 0.8148582577705383, 0.754504382610321, 0.6003425121307373]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   24  | 0.5563133024439519 | 0.5448050669261387 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 25:
0.5523882298445215
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5755914449691772, 0.8179190158843994, 0.5770642161369324, 0.5723049640655518, 0.820179283618927, 0.8184180855751038, 0.6254680752754211]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   25  | 0.5523882298445215 | 0.5193999537399837 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 26:
0.5534819379752997
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.570265531539917, 0.8194777369499207, 0.6039934158325195, 0.5696194767951965, 0.8225261569023132, 0.8204821944236755, 0.5967484712600708]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   26  | 0.5534819379752997 | 0.5317976325750351 | 0.5714285714285714 | 0.9166666666666667 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 27:
0.5194196500340287
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5653296709060669, 0.8241204619407654, 0.5658712983131409, 0.5601444244384766, 0.826316773891449, 0.8259398341178894, 0.7563775181770325]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   27  | 0.5194196500340287 | 0.4776506019490106 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 28:
0.5152803422236929
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5551162362098694, 0.8296119570732117, 0.5569556355476379, 0.5527392029762268, 0.8304222226142883, 0.8291724324226379, 0.6269974708557129]
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
|   28  | 0.5152803422236929 | 0.49362845505986896 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 29:
0.5247653041567121
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5447560548782349, 0.8331379890441895, 0.5446377396583557, 0.542951226234436, 0.8332058787345886, 0.82337886095047, 0.5933541059494019]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   29  | 0.5247653041567121 | 0.4911260391984667 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 30:
0.5755152434718852
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5434837341308594, 0.828140139579773, 0.5428494215011597, 0.5421751141548157, 0.8330616354942322, 0.8014400005340576, 0.5682648420333862]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   30  | 0.5755152434718852 | 0.500839324934142 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 31:
0.533968344634893
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5408758521080017, 0.8341895937919617, 0.5395886301994324, 0.5395626425743103, 0.8338656425476074, 0.8283342719078064, 0.5587964653968811]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   31  | 0.533968344634893 | 0.4947048659835543 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 32:
0.5277275680279245
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5373477339744568, 0.8370665311813354, 0.5379096269607544, 0.5358836650848389, 0.8374115228652954, 0.8306015133857727, 0.574707567691803]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   32  | 0.5277275680279245 | 0.4864549764565059 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 33:
0.5351176788004077
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5425305962562561, 0.8388441801071167, 0.5448874831199646, 0.537590742111206, 0.8400779962539673, 0.8364800214767456, 0.7971727848052979]
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
|   33  | 0.5351176788004077 | 0.44225544376032694 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 34:
0.5066325509426545
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5332034826278687, 0.842278778553009, 0.5321875810623169, 0.5292357206344604, 0.8425781726837158, 0.8351633548736572, 0.6979275345802307]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   34  | 0.5066325509426545 | 0.4510926455259323 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 35:
0.5120729542508418
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5222979784011841, 0.8427554368972778, 0.5272070169448853, 0.5205806493759155, 0.8437135219573975, 0.8437488079071045, 0.7921680212020874]
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
|   35  | 0.5120729542508418 | 0.42384975935731617 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 36:
0.5440641538221009
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5201377868652344, 0.8438447117805481, 0.5190297365188599, 0.5189240574836731, 0.8425307869911194, 0.84312903881073, 0.6311915516853333]
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
|   36  | 0.5440641538221009 | 0.45283560880592894 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 37:
0.5362927755531
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5166874527931213, 0.8437105417251587, 0.5152168273925781, 0.5127084851264954, 0.8450421094894409, 0.8413808941841125, 0.5755350589752197]
+-------+-----------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |    Train Loss   |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-----------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   37  | 0.5362927755531 | 0.4619312307664326 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-----------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 38:
0.5251029644693647
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.513261079788208, 0.847141683101654, 0.512462317943573, 0.510723888874054, 0.8470116853713989, 0.8443142175674438, 0.5851160287857056]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   38  | 0.5251029644693647 | 0.4557638870818274 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 39:
0.5209656342559931
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5104974508285522, 0.8479936718940735, 0.5140284299850464, 0.5106969475746155, 0.8485665917396545, 0.8435308337211609, 0.7543063163757324]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   39  | 0.5209656342559931 | 0.4188497705118997 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 40:
0.5149014233326425
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5034753680229187, 0.8500407934188843, 0.5057580471038818, 0.5017569065093994, 0.8498455286026001, 0.844839870929718, 0.5939691662788391]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   40  | 0.5149014233326425 | 0.4451753092663629 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 41:
0.5101366575275149
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.5049311518669128, 0.8521223664283752, 0.5082924365997314, 0.5005440711975098, 0.8524243235588074, 0.8482710719108582, 0.6637548208236694]
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
|   41  | 0.5101366575275149 | 0.42875127494335175 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 42:
0.48414434887924973
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.4949440360069275, 0.8533400893211365, 0.4942080080509186, 0.493462473154068, 0.8539208769798279, 0.8498993515968323, 0.8281002640724182]
Current metric value better than 1.0 better than best 0.4155844155844156, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124446-exx4y2q9/files/checkpoints/ResInf_epoch42.pt, & logging model weights to W&B.
Removing extra models.. [{'path': '/home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124446-exx4y2q9/files/checkpoints/ResInf_epoch0.pt', 'score': 0.4155844155844156}]
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
| Epoch |      Train Loss     |      Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
|   42  | 0.48414434887924973 | 0.38752070707934244 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 43:
0.4791634307832134
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.49023887515068054, 0.8553938865661621, 0.49025750160217285, 0.48877522349357605, 0.8549853563308716, 0.8550637364387512, 0.6084780693054199]
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
|   43  | 0.4791634307832134 | 0.4264066219329834 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 44:
0.5037702699096835
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.48552849888801575, 0.8565657138824463, 0.485534131526947, 0.4842798411846161, 0.8575138449668884, 0.8558374047279358, 0.8078266978263855]
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
|   44  | 0.5037702699096835 | 0.3812938460281917 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 45:
0.49597399058390634
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.4806150197982788, 0.8589608669281006, 0.48119276762008667, 0.4797375500202179, 0.8593952059745789, 0.8570240139961243, 0.764218807220459]
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
| Epoch |      Train Loss     |      Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
|   45  | 0.49597399058390634 | 0.38450048863887787 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 46:
0.49789922213067817
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.47985050082206726, 0.8606380820274353, 0.4814230799674988, 0.4777511954307556, 0.8606186509132385, 0.8596644401550293, 0.8032216429710388]
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
| Epoch |      Train Loss     |      Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
|   46  | 0.49789922213067817 | 0.37577712322984425 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+---------------------+---------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 47:
0.48995033818848277
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.47536933422088623, 0.8617933988571167, 0.47688740491867065, 0.4725581705570221, 0.8616961240768433, 0.8518557548522949, 0.5666205286979675]
+-------+---------------------+--------------------+----------+-----+-----+-----+--------------------+
| Epoch |      Train Loss     |     Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+---------------------+--------------------+----------+-----+-----+-----+--------------------+
|   47  | 0.48995033818848277 | 0.4226759821176529 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+---------------------+--------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 48:
0.4932016480942162
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.4722285866737366, 0.8633145689964294, 0.4749017059803009, 0.469969779253006, 0.8632056713104248, 0.8607640266418457, 0.7958536744117737]
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
|   48  | 0.4932016480942162 | 0.3700623320681708 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+----------+-----+-----+-----+--------------------+
Total Loss in Epoch 49:
0.5243552169021295
truths [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0] preds [0.4668791592121124, 0.8634892702102661, 0.47064974904060364, 0.46555015444755554, 0.8639649152755737, 0.8620239496231079, 0.8050156235694885]
+-------+--------------------+---------------------+----------+-----+-----+-----+--------------------+
| Epoch |     Train Loss     |      Test Loss      | Accuracy | AUC |  f1 | mcc |      Positive      |
+-------+--------------------+---------------------+----------+-----+-----+-----+--------------------+
|   49  | 0.5243552169021295 | 0.36428460691656384 |   1.0    | 1.0 | 1.0 | 1.0 | 0.5714285714285714 |
+-------+--------------------+---------------------+----------+-----+-----+-----+--------------------+