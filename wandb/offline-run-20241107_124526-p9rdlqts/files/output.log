 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.38it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.16it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.71it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 488.64it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.51it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.24it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.17it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.67it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.56it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.65it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.50it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.81it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.81it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.67it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.21it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 494.80it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.40it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.45it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 133.65it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.40it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.07it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 492.31it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.15it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.31it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.26it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 492.40it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.44it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.78it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.08it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.43it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.29it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.29it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.79it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.92it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.97it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.08it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.22it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.79it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.77it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.85it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 492.78it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 140.09it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.45it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.93it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.83it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.71it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.14it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.73it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.26it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 492.07it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.78it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.55it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.02it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.93it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.30it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.20it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.60it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 494.33it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.77it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.77it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.69it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 492.25it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.38it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 488.07it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.09it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.47it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.83it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.10it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.36it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.46it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.03it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.24it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.95it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.77it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 489.32it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.17it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 491.27it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.31it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 494.00it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.32it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 399.60it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.31it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.72it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.03it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.08it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.18it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.05it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.37it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.28it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.12it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.42it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 133.92it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.02it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.21it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.16it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.28it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 383.41it/s]
ResInf(
  (avg_pool): AdaptiveAvgPool2d(output_size=1)
  (max_pool): AdaptiveMaxPool2d(output_size=1)
  (sharedMLP): Sequential(
    (0): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): ReLU()
    (2): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (encoder_input_layer): Linear(in_features=1, out_features=8, bias=True)
  (positional_encoding_layer): PositionalEncoder(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (linear1): Linear(in_features=8, out_features=8, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=8, out_features=8, bias=True)
        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (gcns): ModuleList(
    (0): GCNConv(
      (linear): Linear(in_features=8, out_features=4, bias=True)
      (s_linear): Linear(in_features=8, out_features=4, bias=True)
    )
  )
  (hidden_layers): ModuleList(
    (0): Linear(in_features=4, out_features=4, bias=True)
    (1): Tanh()
  )
  (resi_net_Linear): Linear(in_features=4, out_features=3, bias=True)
  (resi_net_down): Linear(in_features=3, out_features=1, bias=True)
  (pred_linear): Linear(in_features=1, out_features=1, bias=True)
)
Namespace(lr=0.001, weight_decay=1e-05, dropout=0, hidden=2, time_tick=100, gpu=0, seed=2021, T=200.0, operator='norm_adj', epoch=50, train_size=1, valid_size=1, test_size=1, rand_guess=False, layers=1, use='start', type='node', causal=0, K=2, comment='normal', mech=1, asso=0, use_model='resinf', decompo='None', cross=0, save=1, emb_size=4, hidden_layers_num=2, pool_type='virtual', pool_arch='global', trans_layers=1, trans_emb_size=8, n_heads=1, finetune=0, train_type='kfold', threshold=0.5, fold_num=8, use_logitloss=False, use_wandb=True)
Total Loss in Epoch 0:
0.6575347075656969
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5847253203392029, 0.5842028856277466, 0.582848072052002, 0.5844359397888184, 0.5843843817710876, 0.5802808403968811, 0.5815706849098206]
Current metric value better than 0.5952380952380951 better than best -inf, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124526-p9rdlqts/files/checkpoints/ResInf_epoch0.pt, & logging model weights to W&B.
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   0   | 0.6575347075656969 | 0.636681718485696 | 0.7142857142857143 | 0.2 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 1:
0.6566054638551206
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5899619460105896, 0.5910310745239258, 0.5916436910629272, 0.5891228318214417, 0.5904875993728638, 0.5872815847396851, 0.5877453684806824]
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   1   | 0.6566054638551206 | 0.6328731008938381 | 0.7142857142857143 | 0.30000000000000004 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 2:
0.6524688589329622
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5961094498634338, 0.5982049703598022, 0.598284900188446, 0.5947749018669128, 0.598504900932312, 0.5944011807441711, 0.5971807837486267]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   2   | 0.6524688589329622 | 0.628677385193961 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 3:
0.6511791007859367
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6045446991920471, 0.6026706695556641, 0.6043619513511658, 0.6016885042190552, 0.6055505871772766, 0.6016017198562622, 0.6045891046524048]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   3   | 0.6511791007859367 | 0.6250411101749965 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 4:
0.6496171337001178
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6089100241661072, 0.6095396876335144, 0.6074718832969666, 0.604492723941803, 0.6096072196960449, 0.6050145030021667, 0.6074470281600952]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   4   | 0.6496171337001178 | 0.6252850294113159 | 0.7142857142857143 | 0.2 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 5:
0.6484306089732111
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6065472364425659, 0.6090267896652222, 0.6111694574356079, 0.6086801886558533, 0.6108980178833008, 0.6092322468757629, 0.6078991889953613]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   5   | 0.6484306089732111 | 0.6209830003125327 | 0.7142857142857143 | 0.8 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 6:
0.6493293892364113
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.617389976978302, 0.6150844693183899, 0.6192476153373718, 0.6166777610778809, 0.6184921264648438, 0.6094492077827454, 0.613932192325592]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   6   | 0.6493293892364113 | 0.6202386319637299 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 7:
0.6491790760536583
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6194804906845093, 0.6157752275466919, 0.620969295501709, 0.6179436445236206, 0.6181555390357971, 0.6136561632156372, 0.6166109442710876]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   7   | 0.6491790760536583 | 0.6190614019121442 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 8:
0.6479003338181243
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6260905265808105, 0.627083957195282, 0.6271456480026245, 0.6253542304039001, 0.6262566447257996, 0.6193918585777283, 0.6081290245056152]
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   8   | 0.6479003338181243 | 0.6215053413595472 | 0.7142857142857143 | 0.30000000000000004 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 9:
0.6468055400313163
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6244912147521973, 0.6298651099205017, 0.6315411925315857, 0.6299827694892883, 0.6312627196311951, 0.6287338733673096, 0.6301640272140503]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   9   | 0.6468055400313163 | 0.6115530814443316 | 0.7142857142857143 | 0.9 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 10:
0.6484510393775239
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6202558279037476, 0.629896342754364, 0.6284772753715515, 0.6243565678596497, 0.6294426918029785, 0.6249666213989258, 0.6292040944099426]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   10  | 0.6484510393775239 | 0.6134279796055385 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 11:
0.646397624697004
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6332986354827881, 0.6338760852813721, 0.6343134641647339, 0.6318303942680359, 0.6338722705841064, 0.6325184106826782, 0.633339524269104]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   11  | 0.646397624697004 | 0.6132913657597133 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 12:
0.6440543185691444
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6335130929946899, 0.6352933049201965, 0.635911762714386, 0.6349546909332275, 0.6358407139778137, 0.6304042339324951, 0.6310473084449768]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   12  | 0.6440543185691444 | 0.6134181618690491 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 13:
0.6445172082404701
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6090357303619385, 0.6339225769042969, 0.6385741233825684, 0.6389188766479492, 0.639319658279419, 0.6372254490852356, 0.6354647874832153]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   13  | 0.6445172082404701 | 0.5988465632711139 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 14:
0.6500884963541614
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6398722529411316, 0.6359995007514954, 0.6398745775222778, 0.6334435343742371, 0.6394950747489929, 0.6327794194221497, 0.6378968358039856]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   14  | 0.6500884963541614 | 0.6127503642014095 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 15:
0.6444771235086479
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6295848488807678, 0.6453653573989868, 0.6455757021903992, 0.6441419720649719, 0.6460732221603394, 0.6455400586128235, 0.6427235007286072]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   15  | 0.6444771235086479 | 0.6033997322831836 | 0.7142857142857143 | 0.8 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 16:
0.6424877035374544
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6409872174263, 0.6440365314483643, 0.644551157951355, 0.6428513526916504, 0.6445184946060181, 0.6405208706855774, 0.6412516832351685]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   16  | 0.6424877035374544 | 0.6096322621617999 | 0.7142857142857143 | 0.6000000000000001 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 17:
0.6456587758599496
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6453835964202881, 0.6452825665473938, 0.6455830931663513, 0.6444563269615173, 0.6455456018447876, 0.6441552639007568, 0.6453065276145935]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   17  | 0.6456587758599496 | 0.6093723944255284 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 18:
0.6428684111760588
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6496376395225525, 0.6495030522346497, 0.6495105624198914, 0.6493837833404541, 0.6497952938079834, 0.6478577256202698, 0.6486468315124512]
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   18  | 0.6428684111760588 | 0.6083581617900303 | 0.7142857142857143 | 0.30000000000000004 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 19:
0.6444379267643909
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6470727920532227, 0.6477199196815491, 0.6476800441741943, 0.646691620349884, 0.6472212076187134, 0.6466472744941711, 0.6477611064910889]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   19  | 0.6444379267643909 | 0.6086173057556152 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 20:
0.6414374550994562
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6489423513412476, 0.6490656137466431, 0.6492129564285278, 0.6484695076942444, 0.6491572260856628, 0.6475481390953064, 0.6488467454910278]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   20  | 0.6414374550994562 | 0.6083281295640128 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 21:
0.6374505551493898
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6420657634735107, 0.654961347579956, 0.6548851728439331, 0.6372841000556946, 0.6548894643783569, 0.6361055374145508, 0.6546633839607239]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   21  | 0.6374505551493898 | 0.609236227614539 | 0.7142857142857143 | 0.3 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 22:
0.6424992686631729
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6537166237831116, 0.6540576815605164, 0.6546875238418579, 0.6543139815330505, 0.6545413136482239, 0.654059886932373, 0.6543487310409546]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   22  | 0.6424992686631729 | 0.6060340191636767 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 23:
0.6495248407733684
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6566118001937866, 0.656596839427948, 0.6566731929779053, 0.6561588644981384, 0.6567471623420715, 0.6555652618408203, 0.6563698649406433]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   23  | 0.6495248407733684 | 0.606201342173985 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 24:
0.6376490927472407
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6557715535163879, 0.6556383371353149, 0.654615581035614, 0.654775083065033, 0.655810534954071, 0.6554418206214905, 0.6557084321975708]
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   24  | 0.6376490927472407 | 0.6065787630421775 | 0.7142857142857143 | 0.30000000000000004 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 25:
0.6442566787709996
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6542754173278809, 0.6552460193634033, 0.655376672744751, 0.6552355885505676, 0.6555802226066589, 0.6548894643783569, 0.6548957228660583]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   25  | 0.6442566787709996 | 0.6058778975691114 | 0.7142857142857143 | 0.7 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 26:
0.6361078102977908
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6565651893615723, 0.6565370559692383, 0.6566064953804016, 0.656342625617981, 0.6558448076248169, 0.6563147306442261, 0.6560055017471313]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   26  | 0.6361078102977908 | 0.6062441085066114 | 0.7142857142857143 | 0.2 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 27:
0.6513759074162464
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6558824181556702, 0.6559725999832153, 0.655767560005188, 0.6547315716743469, 0.655670702457428, 0.6553793549537659, 0.655753493309021]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   27  | 0.6513759074162464 | 0.6065560962472644 | 0.7142857142857143 | 0.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 28:
0.6415239262337588
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6585023999214172, 0.6573130488395691, 0.6585285067558289, 0.6583957076072693, 0.6585274934768677, 0.6584310531616211, 0.6583070158958435]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   28  | 0.6415239262337588 | 0.6049682072230748 | 0.7142857142857143 | 0.7 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 29:
0.6435546564812563
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6568170785903931, 0.6565044522285461, 0.6569151282310486, 0.6562682390213013, 0.6567738056182861, 0.6563374400138855, 0.6567565202713013]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   29  | 0.6435546564812563 | 0.6059138008526394 | 0.7142857142857143 | 0.4 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 30:
0.6395749115214056
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.65732342004776, 0.6574004888534546, 0.6573027968406677, 0.6562478542327881, 0.6572778820991516, 0.6568267345428467, 0.6569264531135559]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   30  | 0.6395749115214056 | 0.6061650174004691 | 0.7142857142857143 | 0.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 31:
0.6386698046509101
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6579648852348328, 0.6579575538635254, 0.6579517126083374, 0.6576921343803406, 0.6580148935317993, 0.6577169895172119, 0.6578280925750732]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   31  | 0.6386698046509101 | 0.6056606130940574 | 0.7142857142857143 | 0.2 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 32:
0.6297761463389104
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5650739073753357, 0.6188289523124695, 0.6604819297790527, 0.6052067279815674, 0.660956084728241, 0.6569008231163025, 0.6604095101356506]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   32  | 0.6297761463389104 | 0.5661774575710297 | 0.7142857142857143 | 0.9 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 33:
0.6525390129916522
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6607924699783325, 0.6612063646316528, 0.6612477898597717, 0.6607261300086975, 0.661188542842865, 0.6606864929199219, 0.6550938487052917]
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |         AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
|   33  | 0.6525390129916522 | 0.6061026539121356 | 0.7142857142857143 | 0.30000000000000004 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+---------------------+--------------------+-----+--------------------+
Total Loss in Epoch 34:
0.652092017081319
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6570878028869629, 0.6485267281532288, 0.6559110879898071, 0.6136691570281982, 0.6588908433914185, 0.6205747127532959, 0.6571395993232727]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   34  | 0.652092017081319 | 0.6200138926506042 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 35:
0.6378857815752224
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6095407605171204, 0.6568021774291992, 0.6152321100234985, 0.6454195380210876, 0.6616501808166504, 0.6499276161193848, 0.6529457569122314]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   35  | 0.6378857815752224 | 0.6005234505449023 | 0.7142857142857143 | 0.6 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 36:
0.6567666153518521
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6620880365371704, 0.6637076139450073, 0.6637755036354065, 0.6601752638816833, 0.6638036370277405, 0.6633122563362122, 0.6298641562461853]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   36  | 0.6567666153518521 | 0.6117621319634574 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 37:
0.6480474125365822
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6627643704414368, 0.6622257232666016, 0.662710964679718, 0.6438531875610352, 0.6622016429901123, 0.6626050472259521, 0.6623364090919495]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   37  | 0.6480474125365822 | 0.6085421144962311 | 0.7142857142857143 | 0.3 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 38:
0.6413344941577133
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6411129236221313, 0.5862740278244019, 0.6564120054244995, 0.6468917727470398, 0.6618618965148926, 0.66100013256073, 0.6225613355636597]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   38  | 0.6413344941577133 | 0.5806363608155932 | 0.7142857142857143 | 0.9 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 39:
0.6512685983764882
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6590726971626282, 0.5680897831916809, 0.6606305241584778, 0.6606813669204712, 0.6625698804855347, 0.662391185760498, 0.6626443862915039]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   39  | 0.6512685983764882 | 0.5685304020132337 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 40:
0.653427718853464
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6559478044509888, 0.637114405632019, 0.6609171032905579, 0.6607035398483276, 0.6607062220573425, 0.6539455056190491, 0.6059286594390869]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   40  | 0.653427718853464 | 0.6070538205759866 | 0.7142857142857143 | 0.7 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 41:
0.6620966640053964
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6599459052085876, 0.5572258830070496, 0.6585986614227295, 0.6600164771080017, 0.659869372844696, 0.65738844871521, 0.5690357685089111]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   41  | 0.6620966640053964 | 0.5893547364643642 | 0.7142857142857143 | 0.6 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 42:
0.6341094812568353
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5484487414360046, 0.6389846205711365, 0.6627361178398132, 0.6627911925315857, 0.6627271175384521, 0.6629219651222229, 0.657839298248291]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   42  | 0.6341094812568353 | 0.553979903459549 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 43:
0.639476553517945
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.658644437789917, 0.6616358160972595, 0.661672055721283, 0.6505752205848694, 0.6625710129737854, 0.6399428844451904, 0.6625845432281494]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   43  | 0.639476553517945 | 0.6101368154798236 | 0.7142857142857143 | 0.6 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 44:
0.6397420751805208
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.545124888420105, 0.6592116355895996, 0.6643694043159485, 0.6332668662071228, 0.6647578477859497, 0.6544216871261597, 0.6434957981109619]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   44  | 0.6397420751805208 | 0.5718831249645778 | 0.7142857142857143 | 0.7 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 45:
0.6419236057875107
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6150883436203003, 0.557918906211853, 0.6492056250572205, 0.6630103588104248, 0.6634411811828613, 0.662204921245575, 0.5475960969924927]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   45  | 0.6419236057875107 | 0.5769552120140621 | 0.7142857142857143 | 0.8 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 46:
0.6367637083238485
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5339502096176147, 0.5381889343261719, 0.6665855646133423, 0.5826760530471802, 0.6694926619529724, 0.661738395690918, 0.6623396873474121]
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
|   46  | 0.6367637083238485 | 0.529695668390819 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+-------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 47:
0.648565802647143
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6170270442962646, 0.6555498838424683, 0.6668968796730042, 0.6655142307281494, 0.666825532913208, 0.6621649265289307, 0.6673147678375244]
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   47  | 0.648565802647143 | 0.5799818549837384 | 0.7142857142857143 | 1.0 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+-------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 48:
0.6561643718456736
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.5835234522819519, 0.6683080792427063, 0.6677049994468689, 0.6617134809494019, 0.6680423021316528, 0.6566937565803528, 0.6668373346328735]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   48  | 0.6561643718456736 | 0.5750651104109628 | 0.7142857142857143 | 0.5 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 49:
0.6439452992410076
truths [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0] preds [0.6633533239364624, 0.6628493666648865, 0.6693140864372253, 0.6689399480819702, 0.6695126891136169, 0.6690762042999268, 0.6483798027038574]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   49  | 0.6439452992410076 | 0.6022643787520272 | 0.7142857142857143 | 0.8 | 0.5952380952380951 | 0.0 | 0.7142857142857143 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+