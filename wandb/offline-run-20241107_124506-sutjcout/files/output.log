 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.19it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.50it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.96it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.43it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.75it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.22it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.63it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.63it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.21it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.18it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.80it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.68it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 140.43it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.96it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.59it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.57it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.34it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.18it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.03it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.59it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 472.60it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.43it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.84it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.18it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.81it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.62it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.95it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.39it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.11it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.45it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.37it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.90it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 140.94it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.72it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.99it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.57it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.08it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.10it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 133.76it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.10it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.63it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.65it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.98it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.86it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 139.92it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.06it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 132.79it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 465.49it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.29it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.05it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.82it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.08it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.94it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.08it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.45it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 481.98it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.46it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.23it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.13it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.54it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 132.59it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.15it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.67it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.32it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.91it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.39it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.33it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 482.26it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.06it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.68it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.73it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.24it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.33it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 480.41it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.49it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.19it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.57it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 486.16it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.53it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 478.65it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.73it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 479.89it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.95it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 484.00it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.30it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.00it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 136.09it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.89it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 134.19it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 485.89it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.65it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 488.12it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 135.24it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.50it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 137.75it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 490.06it/s]
 98%|█████████████████████████████████████████▏| 49/50 [00:00<00:00, 138.13it/s]
 88%|██████████████████████████████████████▌     | 7/8 [00:00<00:00, 483.62it/s]
ResInf(
  (avg_pool): AdaptiveAvgPool2d(output_size=1)
  (max_pool): AdaptiveMaxPool2d(output_size=1)
  (sharedMLP): Sequential(
    (0): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): ReLU()
    (2): Conv2d(1, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (encoder_input_layer): Linear(in_features=1, out_features=8, bias=True)
  (positional_encoding_layer): PositionalEncoder(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (linear1): Linear(in_features=8, out_features=8, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=8, out_features=8, bias=True)
        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (gcns): ModuleList(
    (0): GCNConv(
      (linear): Linear(in_features=8, out_features=4, bias=True)
      (s_linear): Linear(in_features=8, out_features=4, bias=True)
    )
  )
  (hidden_layers): ModuleList(
    (0): Linear(in_features=4, out_features=4, bias=True)
    (1): Tanh()
  )
  (resi_net_Linear): Linear(in_features=4, out_features=3, bias=True)
  (resi_net_down): Linear(in_features=3, out_features=1, bias=True)
  (pred_linear): Linear(in_features=1, out_features=1, bias=True)
)
Namespace(lr=0.001, weight_decay=1e-05, dropout=0, hidden=2, time_tick=100, gpu=0, seed=2021, T=200.0, operator='norm_adj', epoch=50, train_size=1, valid_size=1, test_size=1, rand_guess=False, layers=1, use='start', type='node', causal=0, K=2, comment='normal', mech=1, asso=0, use_model='resinf', decompo='None', cross=0, save=1, emb_size=4, hidden_layers_num=2, pool_type='virtual', pool_arch='global', trans_layers=1, trans_emb_size=8, n_heads=1, finetune=0, train_type='kfold', threshold=0.5, fold_num=8, use_logitloss=False, use_wandb=True)
Total Loss in Epoch 0:
0.6749576013915393
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5340834856033325, 0.5316396951675415, 0.5329028367996216, 0.5324870347976685, 0.5310121178627014, 0.5323925018310547, 0.534226655960083]
Current metric value better than 0.4155844155844156 better than best -inf, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124506-sutjcout/files/checkpoints/ResInf_epoch0.pt, & logging model weights to W&B.
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   0   | 0.6749576013915393 | 0.6847108772822789 | 0.5714285714285714 | 0.8333333333333334 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 1:
0.6665219153676715
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.556027889251709, 0.5577489137649536, 0.5555131435394287, 0.5533623099327087, 0.5556111335754395, 0.5566511154174805, 0.5571056008338928]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   1   | 0.6665219153676715 | 0.6820154019764492 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 2:
0.6583959338616352
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5656642317771912, 0.5678586959838867, 0.5691519975662231, 0.5676711201667786, 0.5636579394340515, 0.5630404949188232, 0.5692873001098633]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   2   | 0.6583959338616352 | 0.6797753317015511 | 0.5714285714285714 | 0.9166666666666667 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 3:
0.6506252945685873
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5941365361213684, 0.5973317623138428, 0.5896795988082886, 0.5998920202255249, 0.5926881432533264, 0.5908757448196411, 0.5956366062164307]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   3   | 0.6506252945685873 | 0.6843089376177106 | 0.5714285714285714 | 0.5 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 4:
0.6431247020254329
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6072964668273926, 0.6013895273208618, 0.5933894515037537, 0.5992037057876587, 0.5840770602226257, 0.6046208739280701, 0.606438934803009]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   4   | 0.6431247020254329 | 0.6783962377480098 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 5:
0.6366926741843321
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6215810179710388, 0.6273212432861328, 0.5916239619255066, 0.600436270236969, 0.5960497856140137, 0.6087360382080078, 0.630378007888794]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   5   | 0.6366926741843321 | 0.6700462400913239 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 6:
0.6313046788682743
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6164506077766418, 0.6302827000617981, 0.6217778921127319, 0.6251716017723083, 0.6147486567497253, 0.62456876039505, 0.6160510778427124]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   6   | 0.6313046788682743 | 0.6885411313601902 | 0.5714285714285714 | 0.5 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 7:
0.628774032909043
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6254435777664185, 0.6348713636398315, 0.6170438528060913, 0.6142991185188293, 0.618361234664917, 0.6382169127464294, 0.6550804376602173]
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   7   | 0.628774032909043 | 0.6803034160818372 | 0.5714285714285714 | 0.6666666666666667 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 8:
0.6267605606390505
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6461760997772217, 0.612894594669342, 0.6219627857208252, 0.6116023063659668, 0.5996320247650146, 0.6299444437026978, 0.6573092937469482]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   8   | 0.6267605606390505 | 0.6679885642869132 | 0.5714285714285714 | 0.8333333333333334 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 9:
0.6163046226209524
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6187794208526611, 0.6229438185691833, 0.6000562906265259, 0.6052945256233215, 0.6145920753479004, 0.621800422668457, 0.6567978858947754]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   9   | 0.6163046226209524 | 0.6771168240479061 | 0.5714285714285714 | 0.6666666666666666 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 10:
0.6097620950669659
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6381475925445557, 0.6264942288398743, 0.5819650888442993, 0.5973058938980103, 0.5857143998146057, 0.6060377359390259, 0.6741620302200317]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   10  | 0.6097620950669659 | 0.6535298526287079 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 11:
0.6024167847876646
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6253582239151001, 0.6669028401374817, 0.5858014225959778, 0.5980739593505859, 0.5930241942405701, 0.61654132604599, 0.683541476726532]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   11  | 0.6024167847876646 | 0.6512565783091954 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 12:
0.6003401236874717
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.617935061454773, 0.6295672655105591, 0.6015147566795349, 0.5953118205070496, 0.5722377896308899, 0.5966904163360596, 0.7033271193504333]
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
|   12  | 0.6003401236874717 | 0.6380298605987004 | 0.5714285714285714 | 1.0 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+-----+--------------------+-----+--------------------+
Total Loss in Epoch 13:
0.5895102474154258
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6129143834114075, 0.6081660389900208, 0.5413333773612976, 0.5606960654258728, 0.5765355825424194, 0.5610204935073853, 0.6996319890022278]
+-------+--------------------+-------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+------+--------------------+-----+--------------------+
|   13  | 0.5895102474154258 | 0.637558604989733 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 14:
0.576757189570641
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6830716133117676, 0.6254122853279114, 0.5655168890953064, 0.5809484720230103, 0.5750004053115845, 0.5946630835533142, 0.7254607677459717]
+-------+-------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+-------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   14  | 0.576757189570641 | 0.6242754714829581 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 15:
0.5702379631752871
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6682283282279968, 0.6260634660720825, 0.5182116627693176, 0.5634219646453857, 0.5430148243904114, 0.5592405200004578, 0.7419849634170532]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   15  | 0.5702379631752871 | 0.6083393011774335 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 16:
0.5585418404365072
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5654919147491455, 0.6243217587471008, 0.5195966958999634, 0.5302841663360596, 0.5490826368331909, 0.5380842089653015, 0.7655782103538513]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   16  | 0.5585418404365072 | 0.6124923186642783 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 17:
0.5393099267872012
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5625442862510681, 0.6273949146270752, 0.501366376876831, 0.5075599551200867, 0.5210649371147156, 0.5011700391769409, 0.7490484714508057]
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      |        AUC         |         f1         | mcc |      Positive      |
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+-----+--------------------+
|   17  | 0.5393099267872012 | 0.594413868018559 | 0.5714285714285714 | 0.8333333333333334 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+-----+--------------------+
Total Loss in Epoch 18:
0.5522495055077027
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.641292929649353, 0.6730568408966064, 0.5075733065605164, 0.5097627639770508, 0.5162110328674316, 0.5420883297920227, 0.7866463661193848]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   18  | 0.5522495055077027 | 0.5683337599039078 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 19:
0.5216089529650552
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6287278532981873, 0.5959194302558899, 0.5011879205703735, 0.5553598403930664, 0.5170733332633972, 0.537736713886261, 0.7806638479232788]
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
|   19  | 0.5216089529650552 | 0.6042989236967904 | 0.5714285714285714 | 0.75 | 0.4155844155844156 | 0.0 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+-----+--------------------+
Total Loss in Epoch 20:
0.5046062542467701
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7263265252113342, 0.5813650488853455, 0.4747091829776764, 0.5351854562759399, 0.48095476627349854, 0.504858672618866, 0.7946681976318359]
Current metric value better than 0.5523809523809523 better than best 0.4155844155844156, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124506-sutjcout/files/checkpoints/ResInf_epoch20.pt, & logging model weights to W&B.
Removing extra models.. [{'path': '/home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124506-sutjcout/files/checkpoints/ResInf_epoch0.pt', 'score': 0.4155844155844156}]
+-------+--------------------+-------------------+--------------------+------+--------------------+---------------------+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC  |         f1         |         mcc         |      Positive      |
+-------+--------------------+-------------------+--------------------+------+--------------------+---------------------+--------------------+
|   20  | 0.5046062542467701 | 0.565972660269056 | 0.5714285714285714 | 0.75 | 0.5523809523809523 | 0.09128709291752768 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+------+--------------------+---------------------+--------------------+
Total Loss in Epoch 21:
0.5208977679817044
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7054204344749451, 0.560584545135498, 0.47069254517555237, 0.4855482876300812, 0.4661445915699005, 0.4826502501964569, 0.8100106716156006]
Current metric value better than 0.8571428571428571 better than best 0.5523809523809523, saving model at /home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124506-sutjcout/files/checkpoints/ResInf_epoch21.pt, & logging model weights to W&B.
Removing extra models.. [{'path': '/home/lr2024/project/ResInf-main/wandb/offline-run-20241107_124506-sutjcout/files/checkpoints/ResInf_epoch20.pt', 'score': 0.5523809523809523}]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
|   21  | 0.5208977679817044 | 0.5490449347666332 | 0.8571428571428571 | 0.8333333333333334 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
Total Loss in Epoch 22:
0.5014593135945651
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.49597978591918945, 0.5199563503265381, 0.44657203555107117, 0.4620349109172821, 0.45627251267433167, 0.47148340940475464, 0.8165080547332764]
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         |        mcc         |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
|   22  | 0.5014593135945651 | 0.6044361931937081 | 0.7142857142857143 | 0.75 | 0.7023809523809523 | 0.5477225575051661 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
Total Loss in Epoch 23:
0.5040203913742182
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.634252667427063, 0.5362250208854675, 0.4491199851036072, 0.5594630837440491, 0.4507729113101959, 0.4597241282463074, 0.8139660358428955]
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      |        AUC         |         f1         |        mcc         |      Positive      |
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
|   23  | 0.5040203913742182 | 0.588498688169888 | 0.7142857142857143 | 0.6666666666666666 | 0.7142857142857143 | 0.4166666666666667 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
Total Loss in Epoch 24:
0.49478164619329024
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.571012556552887, 0.5285517573356628, 0.44979846477508545, 0.4760001003742218, 0.45086172223091125, 0.45544421672821045, 0.8316537141799927]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   24  | 0.49478164619329024 | 0.5763867284570422 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 25:
0.4727961387561292
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6940931081771851, 0.6093453168869019, 0.43271803855895996, 0.4948747158050537, 0.46522170305252075, 0.4370296001434326, 0.8371074199676514]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   25  | 0.4727961387561292 | 0.5370530209371022 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 26:
0.4756483390014999
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7710431218147278, 0.5668909549713135, 0.4327428936958313, 0.484635591506958, 0.47825556993484497, 0.46293336153030396, 0.8445488214492798]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   26  | 0.4756483390014999 | 0.5384650145258222 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 27:
0.48274920090120665
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.654761016368866, 0.7846876978874207, 0.4267145097255707, 0.4463585615158081, 0.4378461241722107, 0.44387689232826233, 0.8466995358467102]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   27  | 0.48274920090120665 | 0.4911410297666277 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 28:
0.5355235806533268
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6187043190002441, 0.7575657963752747, 0.42535123229026794, 0.4731106162071228, 0.42942047119140625, 0.5006428360939026, 0.8477545976638794]
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         |        mcc         |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
|   28  | 0.5355235806533268 | 0.5248682690518243 | 0.7142857142857143 | 0.75 | 0.7142857142857143 | 0.4166666666666667 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+--------------------+--------------------+
Total Loss in Epoch 29:
0.48362534082665737
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5506181716918945, 0.7468000054359436, 0.41143515706062317, 0.4694584012031555, 0.42519745230674744, 0.4194468557834625, 0.8506802320480347]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   29  | 0.48362534082665737 | 0.5242648401430675 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 30:
0.49769347054617746
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7081134915351868, 0.7133211493492126, 0.41440895199775696, 0.4728119969367981, 0.4172517657279968, 0.43303966522216797, 0.851564347743988]
+-------+---------------------+---------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |      Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+---------------------+--------------------+------+--------------------+------+--------------------+
|   30  | 0.49769347054617746 | 0.49603151423590525 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+---------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 31:
0.47964415440754016
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6863318085670471, 0.7591967582702637, 0.40823522210121155, 0.43354877829551697, 0.4180218577384949, 0.4413822889328003, 0.8534034490585327]
+-------+---------------------+-------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss     |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+-------------------+--------------------+------+--------------------+------+--------------------+
|   31  | 0.47964415440754016 | 0.485471384865897 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+-------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 32:
0.4709547186384396
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6014444231987, 0.6481462717056274, 0.402013897895813, 0.4358336329460144, 0.4068756699562073, 0.4098578989505768, 0.8558270931243896]
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
|   32  | 0.4709547186384396 | 0.518737827028547 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 33:
0.477158679949994
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7857821583747864, 0.7238941788673401, 0.3987398147583008, 0.4817764163017273, 0.4045526087284088, 0.4052886962890625, 0.8616324067115784]
+-------+-------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss    |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+-------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   33  | 0.477158679949994 | 0.4754326343536377 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+-------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 34:
0.4452782978816908
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6233583092689514, 0.6644037961959839, 0.3882122337818146, 0.41010963916778564, 0.3959059417247772, 0.3952919840812683, 0.8634320497512817]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   34  | 0.4452782978816908 | 0.5013422306094851 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 35:
0.46262411773204803
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6165514588356018, 0.5713208317756653, 0.3862058222293854, 0.45271649956703186, 0.3958113491535187, 0.3913436233997345, 0.8647990226745605]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   35  | 0.46262411773204803 | 0.5347456229584557 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 36:
0.4734819412839656
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5996084809303284, 0.7285544872283936, 0.3861314356327057, 0.4070390462875366, 0.396860271692276, 0.40304961800575256, 0.8673540949821472]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   36  | 0.4734819412839656 | 0.4951730115073068 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 37:
0.4711369026680382
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6754906177520752, 0.7677261233329773, 0.3792855143547058, 0.40318813920021057, 0.38692179322242737, 0.39835718274116516, 0.8689077496528625]
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss     |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
|   37  | 0.4711369026680382 | 0.468590001974787 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+-------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 38:
0.4614201191128517
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7088140845298767, 0.7562001943588257, 0.37402692437171936, 0.4333680272102356, 0.3788298964500427, 0.387419193983078, 0.870870053768158]
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
|   38  | 0.4614201191128517 | 0.46851017219679697 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 39:
0.44177304816489316
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6678770780563354, 0.6445087194442749, 0.37189602851867676, 0.4005929231643677, 0.3789787292480469, 0.4292125403881073, 0.8720294237136841]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   39  | 0.44177304816489316 | 0.5025619779314313 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 40:
0.4555780550046843
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7063343524932861, 0.5264318585395813, 0.376324862241745, 0.4056191146373749, 0.3752368092536926, 0.3826821744441986, 0.8732137680053711]
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      |        AUC         |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
|   40  | 0.4555780550046843 | 0.5107380300760269 | 0.8571428571428571 | 0.8333333333333334 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+
Total Loss in Epoch 41:
0.46093848986285074
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5861594080924988, 0.7453292608261108, 0.36845213174819946, 0.4297298789024353, 0.3740675151348114, 0.3801685571670532, 0.8747014403343201]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   41  | 0.46093848986285074 | 0.4955536297389439 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 42:
0.4842417678054498
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.768002450466156, 0.6982802152633667, 0.3656785786151886, 0.4848296642303467, 0.3733624219894409, 0.38799741864204407, 0.8765817880630493]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   42  | 0.4842417678054498 | 0.4832123283829008 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 43:
0.4429149548618161
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.673355758190155, 0.7971326112747192, 0.36055484414100647, 0.4332972764968872, 0.37324559688568115, 0.37463781237602234, 0.8764932155609131]
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
|   43  | 0.4429149548618161 | 0.46838549630982534 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 44:
0.4533717614047381
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7235329747200012, 0.6326541304588318, 0.35681742429733276, 0.3842846155166626, 0.3624081313610077, 0.37919920682907104, 0.878577709197998]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   44  | 0.4533717614047381 | 0.4790278502873012 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 45:
0.4554934817917493
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.6232903599739075, 0.5951206684112549, 0.3525562882423401, 0.4119260609149933, 0.3544439375400543, 0.35726943612098694, 0.8789694905281067]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   45  | 0.4554934817917493 | 0.5105513568435397 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 46:
0.46140753219322284
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7059584259986877, 0.8160722255706787, 0.3517640233039856, 0.39600878953933716, 0.3539745509624481, 0.3719708323478699, 0.8811258673667908]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   46  | 0.46140753219322284 | 0.4470116389649255 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 47:
0.4509785318252992
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.5557945966720581, 0.7201882004737854, 0.34764623641967773, 0.3714577853679657, 0.3541210889816284, 0.3848990201950073, 0.8815481066703796]
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   47  | 0.4509785318252992 | 0.4979584110634668 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+--------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 48:
0.4333374700984176
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7043523788452148, 0.5995333790779114, 0.342864990234375, 0.3703218400478363, 0.3485688865184784, 0.3511008024215698, 0.883212149143219]
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |     Train Loss     |      Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
|   48  | 0.4333374700984176 | 0.48289950298411505 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+--------------------+---------------------+--------------------+------+--------------------+------+--------------------+
Total Loss in Epoch 49:
0.44637881097744925
truths [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0] preds [0.7965333461761475, 0.8478664755821228, 0.34560421109199524, 0.3860699236392975, 0.34846168756484985, 0.3645486533641815, 0.8844937682151794]
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
| Epoch |      Train Loss     |     Test Loss      |      Accuracy      | AUC  |         f1         | mcc  |      Positive      |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+
|   49  | 0.44637881097744925 | 0.4210617733853204 | 0.8571428571428571 | 0.75 | 0.8571428571428571 | 0.75 | 0.5714285714285714 |
+-------+---------------------+--------------------+--------------------+------+--------------------+------+--------------------+